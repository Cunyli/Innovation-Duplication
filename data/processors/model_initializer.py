#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Model Initializer Module

Handles initialization of OpenAI/Azure models and configuration loading.
"""

import os
from typing import Tuple, Optional, Dict, Any
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings


class ConfigLoader:
    """é…ç½®åŠ è½½å™¨ï¼Œæ”¯æŒå¤šç§é…ç½®æº"""
    
    @staticmethod
    def load_from_streamlit() -> Tuple[bool, Optional[Dict]]:
        """
        å°è¯•ä» Streamlit secrets åŠ è½½é…ç½®
        
        Returns:
            Tuple[bool, Optional[Dict]]: (æ˜¯å¦æˆåŠŸ, é…ç½®å­—å…¸)
        """
        try:
            import streamlit as st
            if hasattr(st, 'secrets') and st.secrets and 'AZURE_OPENAI_API_KEY' in st.secrets:
                print("âœ… ä½¿ç”¨ Streamlit secrets é…ç½®")
                return True, st.secrets
        except ImportError:
            pass
        return False, None
    
    @staticmethod
    def load_from_env_or_json() -> Dict:
        """
        ä» .env æ–‡ä»¶æˆ– azure_config.json åŠ è½½é…ç½®
        
        Returns:
            Dict: é…ç½®å­—å…¸
        """
        from config.config_loader import load_config
        print("ğŸ” å°è¯•ä» .env æ–‡ä»¶æˆ– azure_config.json åŠ è½½é…ç½®...")
        return load_config(prefer_env=True)
    
    @staticmethod
    def extract_model_config(config: Dict, use_streamlit: bool) -> Dict[str, Any]:
        """
        ä»é…ç½®ä¸­æå–æ¨¡å‹é…ç½®
        
        Args:
            config: åŸå§‹é…ç½®å­—å…¸
            use_streamlit: æ˜¯å¦ä½¿ç”¨ Streamlit é…ç½®
        
        Returns:
            Dict: æ¨¡å‹é…ç½®
        """
        if use_streamlit:
            # Streamlit secrets ç»“æ„
            model_name = config.get('default_model', {}).get('name', 'gpt-4o-mini')
            if model_name in config:
                return config[model_name]
            else:
                # ç›´æ¥ä½¿ç”¨æ ¹çº§é…ç½®
                return {
                    'api_key': config.get('AZURE_OPENAI_API_KEY'),
                    'api_base': config.get('AZURE_OPENAI_ENDPOINT'),
                    'api_version': config.get('AZURE_OPENAI_API_VERSION'),
                    'deployment': config.get('AZURE_OPENAI_DEPLOYMENT'),
                    'emb_deployment': config.get('AZURE_OPENAI_EMBEDDING_DEPLOYMENT')
                }
        else:
            # ä» .env æˆ– JSON åŠ è½½çš„é…ç½®ç»“æ„
            model_name = 'gpt-4o-mini'
            return config.get(model_name, {})


class ModelConfigValidator:
    """æ¨¡å‹é…ç½®éªŒè¯å™¨"""
    
    @staticmethod
    def validate(model_config: Dict) -> bool:
        """
        éªŒè¯æ¨¡å‹é…ç½®æ˜¯å¦æœ‰æ•ˆ
        
        Args:
            model_config: æ¨¡å‹é…ç½®å­—å…¸
        
        Returns:
            bool: é…ç½®æ˜¯å¦æœ‰æ•ˆ
        """
        if not model_config or not model_config.get('api_key'):
            print("âŒ é”™è¯¯: æœªæ‰¾åˆ°æœ‰æ•ˆçš„ Azure OpenAI é…ç½®")
            print("è¯·ç¡®ä¿ä»¥ä¸‹ä»»ä¸€é…ç½®æ–¹å¼:")
            print("  1. åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® AZURE_OPENAI_API_KEY ç­‰å˜é‡")
            print("  2. åœ¨ data/keys/azure_config.json ä¸­é…ç½®")
            print("  3. ä½¿ç”¨ Streamlit secrets (ä»…é™Webåº”ç”¨)")
            return False
        return True
    
    @staticmethod
    def normalize_endpoint(api_base: str) -> str:
        """
        è§„èŒƒåŒ– API endpoint
        
        Args:
            api_base: åŸå§‹ API base URL
        
        Returns:
            str: è§„èŒƒåŒ–åçš„ endpoint
        """
        base_endpoint = api_base.split('/openai')[0] if '/openai' in api_base else api_base
        if not base_endpoint.endswith('/'):
            base_endpoint += '/'
        return base_endpoint
    
    @staticmethod
    def infer_embedding_dimension(emb_deployment: str) -> int:
        """
        æ ¹æ®åµŒå…¥æ¨¡å‹åç§°æ¨æ–­å‘é‡ç»´åº¦
        
        Args:
            emb_deployment: åµŒå…¥æ¨¡å‹éƒ¨ç½²åç§°
        
        Returns:
            int: å‘é‡ç»´åº¦
        """
        if 'text-embedding-3-large' in emb_deployment:
            return 3072
        elif 'text-embedding-3-small' in emb_deployment:
            return 1536
        elif 'text-embedding-ada-002' in emb_deployment:
            return 1536
        else:
            # é»˜è®¤ä½¿ç”¨ 1536ï¼ˆæœ€å¸¸è§çš„ç»´åº¦ï¼‰
            print(f"âš ï¸ æœªè¯†åˆ«çš„åµŒå…¥æ¨¡å‹ '{emb_deployment}'ï¼Œä½¿ç”¨é»˜è®¤ç»´åº¦ 1536")
            return 1536


class AzureModelInitializer:
    """Azure æ¨¡å‹åˆå§‹åŒ–å™¨"""
    
    @staticmethod
    def initialize_llm(model_config: Dict, base_endpoint: str) -> AzureChatOpenAI:
        """
        åˆå§‹åŒ– Azure Chat LLM
        
        Args:
            model_config: æ¨¡å‹é…ç½®
            base_endpoint: API endpoint
        
        Returns:
            AzureChatOpenAI: åˆå§‹åŒ–çš„ LLM
        """
        return AzureChatOpenAI(
            api_key=model_config.get('api_key'),
            azure_endpoint=base_endpoint,
            azure_deployment=model_config.get('deployment'),
            api_version=model_config.get('api_version'),
            temperature=0
        )
    
    @staticmethod
    def initialize_embedding_model(
        model_config: Dict, 
        base_endpoint: str, 
        dimension: int
    ) -> AzureOpenAIEmbeddings:
        """
        åˆå§‹åŒ– Azure åµŒå…¥æ¨¡å‹
        
        Args:
            model_config: æ¨¡å‹é…ç½®
            base_endpoint: API endpoint
            dimension: åµŒå…¥ç»´åº¦
        
        Returns:
            AzureOpenAIEmbeddings: åˆå§‹åŒ–çš„åµŒå…¥æ¨¡å‹
        """
        emb_api_version = model_config.get('emb_api_version', model_config.get('api_version'))
        return AzureOpenAIEmbeddings(
            api_key=model_config.get('api_key'),
            azure_endpoint=base_endpoint,
            azure_deployment=model_config.get('emb_deployment'),
            api_version=emb_api_version,
            dimensions=dimension
        )


def initialize_openai_client() -> Tuple[Optional[AzureChatOpenAI], Optional[AzureOpenAIEmbeddings]]:
    """
    åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ï¼Œä¼˜å…ˆä½¿ç”¨ .env é…ç½®
    
    Returns:
        Tuple[Optional[AzureChatOpenAI], Optional[AzureOpenAIEmbeddings]]: 
            (LLM æ¨¡å‹, åµŒå…¥æ¨¡å‹)
    """
    # æ‰“å°è°ƒè¯•ä¿¡æ¯
    print("=" * 50)
    print("åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯...")
    print(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    
    try:
        # 1. åŠ è½½é…ç½®
        use_streamlit, config = ConfigLoader.load_from_streamlit()
        if not use_streamlit:
            config = ConfigLoader.load_from_env_or_json()
        
        # 2. æå–æ¨¡å‹é…ç½®
        model_config = ConfigLoader.extract_model_config(config, use_streamlit)
        
        # 3. éªŒè¯é…ç½®
        if not ModelConfigValidator.validate(model_config):
            return None, None
        
        # 4. è§„èŒƒåŒ– endpoint
        base_endpoint = ModelConfigValidator.normalize_endpoint(
            model_config.get('api_base', '')
        )
        
        # 5. æ¨æ–­åµŒå…¥ç»´åº¦
        emb_deployment = model_config.get('emb_deployment', '')
        dimension = ModelConfigValidator.infer_embedding_dimension(emb_deployment)
        
        # æ‰“å°é…ç½®ä¿¡æ¯
        print(f"âœ… ä½¿ç”¨æ¨¡å‹: {model_config.get('deployment')}")
        print(f"âœ… ä½¿ç”¨åµŒå…¥æ¨¡å‹: {emb_deployment}")
        print(f"â„¹ï¸  åµŒå…¥å‘é‡ç»´åº¦: {dimension}")
        
        # 6. åˆå§‹åŒ–æ¨¡å‹
        llm = AzureModelInitializer.initialize_llm(model_config, base_endpoint)
        embedding_model = AzureModelInitializer.initialize_embedding_model(
            model_config, base_endpoint, dimension
        )
        
        return llm, embedding_model
        
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯æ—¶å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        return None, None
