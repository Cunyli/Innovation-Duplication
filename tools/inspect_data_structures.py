#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
æ•°æ®ç»“æ„æ£€æŸ¥å·¥å…·

è¿™ä¸ªå·¥å…·å¯ä»¥å¸®åŠ©ä½ æ£€æŸ¥å’Œç†è§£ analysis_results çš„ç»“æ„ã€‚
"""

import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from typing import Dict, Any
import json


def print_analysis_results_structure(analysis_results: Dict) -> None:
    """
    æ‰“å° analysis_results çš„è¯¦ç»†ç»“æ„
    
    Args:
        analysis_results: ç½‘ç»œåˆ†æç»“æœ
    """
    print("=" * 70)
    print("ğŸ“Š ANALYSIS_RESULTS ç»“æ„æ£€æŸ¥")
    print("=" * 70)
    print()
    
    # 1. é¡¶å±‚é”®
    print("ğŸ”‘ é¡¶å±‚é”®:")
    for key in analysis_results.keys():
        print(f"  âœ“ {key}")
    print()
    
    # 2. Graph ä¿¡æ¯
    if 'graph' in analysis_results:
        graph = analysis_results['graph']
        print("ğŸ“ˆ graph (NetworkX å›¾å¯¹è±¡):")
        print(f"  - ç±»å‹: {type(graph).__name__}")
        print(f"  - èŠ‚ç‚¹æ•°: {graph.number_of_nodes()}")
        print(f"  - è¾¹æ•°: {graph.number_of_edges()}")
        
        # èŠ‚ç‚¹ç±»å‹ç»Ÿè®¡
        innovation_count = sum(1 for n in graph.nodes() if graph.nodes[n].get('type') == 'Innovation')
        org_count = sum(1 for n in graph.nodes() if graph.nodes[n].get('type') == 'Organization')
        print(f"  - åˆ›æ–°èŠ‚ç‚¹: {innovation_count}")
        print(f"  - ç»„ç»‡èŠ‚ç‚¹: {org_count}")
        
        # ç¤ºä¾‹èŠ‚ç‚¹
        if graph.number_of_nodes() > 0:
            sample_node = list(graph.nodes())[0]
            print(f"  - ç¤ºä¾‹èŠ‚ç‚¹å±æ€§: {dict(graph.nodes[sample_node])}")
        print()
    
    # 3. Stats ä¿¡æ¯
    if 'stats' in analysis_results:
        stats = analysis_results['stats']
        print("ğŸ“Š stats (ç»Ÿè®¡æŒ‡æ ‡):")
        for key, value in stats.items():
            if isinstance(value, float):
                print(f"  - {key}: {value:.2f}")
            else:
                print(f"  - {key}: {value}")
        print()
    
    # 4. Multi-source ä¿¡æ¯
    if 'multi_source' in analysis_results:
        multi_source = analysis_results['multi_source']
        print("ğŸ” multi_source (å¤šæºéªŒè¯åˆ›æ–°):")
        print(f"  - æ•°é‡: {len(multi_source)}")
        
        if multi_source:
            # ç¤ºä¾‹åˆ›æ–°
            sample_id = list(multi_source.keys())[0]
            sample_data = multi_source[sample_id]
            print(f"  - ç¤ºä¾‹ ID: {sample_id}")
            print(f"  - ç¤ºä¾‹æ•°æ®ç»“æ„:")
            for key, value in sample_data.items():
                value_type = type(value).__name__
                value_len = len(value) if hasattr(value, '__len__') else 'N/A'
                print(f"    â€¢ {key}: {value_type} (é•¿åº¦: {value_len})")
                if key == 'names' and value:
                    print(f"      ä¾‹: {list(value)[:2]}")
        print()
    
    # 5. Top orgs ä¿¡æ¯
    if 'top_orgs' in analysis_results:
        top_orgs = analysis_results['top_orgs']
        print("ğŸ¢ top_orgs (æœ€æ´»è·ƒç»„ç»‡):")
        print(f"  - æ•°é‡: {len(top_orgs)}")
        if top_orgs:
            print(f"  - ç±»å‹: List[Tuple[str, int]]")
            print(f"  - Top 3:")
            for i, (org_id, count) in enumerate(top_orgs[:3], 1):
                print(f"    {i}. {org_id}: {count} ä¸ªåˆ›æ–°")
        print()
    
    # 6. Key orgs ä¿¡æ¯
    if 'key_orgs' in analysis_results:
        key_orgs = analysis_results['key_orgs']
        print("â­ key_orgs (å…³é”®ç»„ç»‡ - ä»‹æ•°ä¸­å¿ƒæ€§):")
        print(f"  - æ•°é‡: {len(key_orgs)}")
        if key_orgs:
            print(f"  - ç±»å‹: List[Tuple[str, float]]")
            print(f"  - Top 3:")
            for i, (org_id, centrality) in enumerate(key_orgs[:3], 1):
                print(f"    {i}. {org_id}: {centrality:.4f}")
        else:
            print(f"  âš ï¸  ä¸ºç©ºï¼ˆå¯èƒ½ä¸­å¿ƒæ€§è®¡ç®—å¤±è´¥ï¼‰")
        print()
    
    # 7. Key innovations ä¿¡æ¯
    if 'key_innovations' in analysis_results:
        key_innovations = analysis_results['key_innovations']
        print("ğŸš€ key_innovations (å…³é”®åˆ›æ–° - ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§):")
        print(f"  - æ•°é‡: {len(key_innovations)}")
        if key_innovations:
            print(f"  - ç±»å‹: List[Tuple[str, float]]")
            print(f"  - Top 3:")
            for i, (inno_id, centrality) in enumerate(key_innovations[:3], 1):
                print(f"    {i}. {inno_id}: {centrality:.4f}")
        else:
            print(f"  âš ï¸  ä¸ºç©ºï¼ˆå¯èƒ½ä¸­å¿ƒæ€§è®¡ç®—å¤±è´¥ï¼‰")
        print()
    
    print("=" * 70)
    print("âœ… ç»“æ„æ£€æŸ¥å®Œæˆ")
    print("=" * 70)


def create_sample_analysis_results() -> Dict:
    """
    åˆ›å»ºä¸€ä¸ªç¤ºä¾‹ analysis_results ç”¨äºæ¼”ç¤º
    
    Returns:
        Dict: ç¤ºä¾‹ analysis_results
    """
    import networkx as nx
    
    # åˆ›å»ºç¤ºä¾‹å›¾
    G = nx.Graph()
    
    # æ·»åŠ èŠ‚ç‚¹
    G.add_node('innovation_1', type='Innovation', names='AI Assistant', sources=2, developed_by=1)
    G.add_node('innovation_2', type='Innovation', names='Smart Robot', sources=1, developed_by=2)
    G.add_node('org_1', type='Organization', name='Tech Company A')
    G.add_node('org_2', type='Organization', name='Research Lab B')
    
    # æ·»åŠ è¾¹
    G.add_edge('innovation_1', 'org_1', type='DEVELOPED_BY')
    G.add_edge('innovation_2', 'org_1', type='DEVELOPED_BY')
    G.add_edge('innovation_2', 'org_2', type='DEVELOPED_BY')
    
    # åˆ›å»º analysis_results
    analysis_results = {
        'graph': G,
        'stats': {
            'total': 2,
            'avg_sources': 1.5,
            'avg_developers': 1.5,
            'multi_source_count': 1,
            'multi_developer_count': 1
        },
        'multi_source': {
            'innovation_1': {
                'names': {'AI Assistant', 'Smart AI'},
                'descriptions': {'An intelligent assistant'},
                'developed_by': {'org_1'},
                'sources': {'https://example.com/1', 'https://example.com/2'},
                'source_ids': {'doc_1', 'doc_2'},
                'data_sources': {'company_website', 'vtt_website'}
            }
        },
        'top_orgs': [
            ('org_1', 2),
            ('org_2', 1)
        ],
        'key_orgs': [
            ('org_1', 0.3333),
            ('org_2', 0.1667)
        ],
        'key_innovations': [
            ('innovation_1', 0.7071),
            ('innovation_2', 0.7071)
        ]
    }
    
    return analysis_results


def check_serialization_issues(analysis_results: Dict) -> None:
    """
    æ£€æŸ¥åºåˆ—åŒ–å¯èƒ½çš„é—®é¢˜
    
    Args:
        analysis_results: ç½‘ç»œåˆ†æç»“æœ
    """
    print("\nğŸ” åºåˆ—åŒ–æ£€æŸ¥:")
    print("-" * 70)
    
    issues = []
    
    # æ£€æŸ¥ multi_source ä¸­çš„ set
    if 'multi_source' in analysis_results:
        for inno_id, data in analysis_results['multi_source'].items():
            for key, value in data.items():
                if isinstance(value, set):
                    issues.append(f"multi_source[{inno_id}][{key}] æ˜¯ set ç±»å‹")
    
    if issues:
        print("âš ï¸  å‘ç°éœ€è¦è½¬æ¢çš„å­—æ®µ:")
        for issue in issues[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"  - {issue}")
        if len(issues) > 5:
            print(f"  ... è¿˜æœ‰ {len(issues) - 5} ä¸ª")
        print("\nğŸ’¡ å»ºè®®: ä½¿ç”¨ ResultExporter å¯¼å‡ºï¼Œå®ƒä¼šè‡ªåŠ¨å¤„ç† set â†’ list è½¬æ¢")
    else:
        print("âœ… æ²¡æœ‰å‘ç°åºåˆ—åŒ–é—®é¢˜")
    
    print("-" * 70)


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 70)
    print("æ•°æ®ç»“æ„æ£€æŸ¥å·¥å…·")
    print("=" * 70)
    print()
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    print("ğŸ“ åˆ›å»ºç¤ºä¾‹ analysis_results...")
    analysis_results = create_sample_analysis_results()
    print("âœ“ ç¤ºä¾‹æ•°æ®åˆ›å»ºå®Œæˆ\n")
    
    # æ£€æŸ¥ç»“æ„
    print_analysis_results_structure(analysis_results)
    
    # æ£€æŸ¥åºåˆ—åŒ–é—®é¢˜
    check_serialization_issues(analysis_results)
    
    print("\nğŸ’¡ æç¤º:")
    print("  - è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹æ•°æ®ï¼ŒçœŸå®æ•°æ®ä¼šæ›´å¤æ‚")
    print("  - ä½¿ç”¨ export_analysis_results() å¯¼å‡ºæ—¶ä¼šè‡ªåŠ¨å¤„ç†åºåˆ—åŒ–")
    print("  - æŸ¥çœ‹ docs/DATA_STRUCTURES.md äº†è§£å®Œæ•´æ–‡æ¡£")
    print()


if __name__ == '__main__':
    main()
