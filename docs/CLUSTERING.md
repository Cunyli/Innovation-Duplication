# èšç±»ç®—æ³•æ¨¡å—æ–‡æ¡£

## ğŸ“‹ æ¦‚è¿°

æœ¬é¡¹ç›®ä½¿ç”¨å¤šç§èšç±»ç®—æ³•æ¥è¯†åˆ«å’Œåˆå¹¶é‡å¤çš„åˆ›æ–°è®°å½•ã€‚èšç±»æ¨¡å—å·²ç»è¿‡é‡æ„ï¼Œæä¾›ç»Ÿä¸€çš„æ¥å£å’Œå®Œå–„çš„æµ‹è¯•æ”¯æŒã€‚

## ğŸ¯ é‡æ„äº®ç‚¹

æœ¬æ¬¡é‡æ„å°†åŸæœ‰çš„ 50+ è¡Œ if-elif åˆ†æ”¯ç®€åŒ–ä¸ºç»Ÿä¸€çš„æ¥å£è°ƒç”¨ï¼Œæé«˜äº†ä»£ç çš„å¯ç»´æŠ¤æ€§å’Œå¯è¯»æ€§ã€‚

### ä»£ç è´¨é‡æ”¹è¿›

| æŒ‡æ ‡ | é‡æ„å‰ | é‡æ„å | æ”¹è¿› |
|------|--------|--------|------|
| ä»£ç è¡Œæ•° | ~50 è¡Œ | ~15 è¡Œ | â¬‡ï¸ 70% |
| åœˆå¤æ‚åº¦ | é«˜ï¼ˆ4+ åˆ†æ”¯ï¼‰ | ä½ï¼ˆ1 ä¸ªè°ƒç”¨ï¼‰ | â¬‡ï¸ æ˜¾è‘—é™ä½ |
| é‡å¤ä»£ç  | é«˜ | æ—  | âœ… æ¶ˆé™¤ |
| å¯è¯»æ€§ | ä¸­ç­‰ | é«˜ | â¬†ï¸ æå‡ |
| å¯ç»´æŠ¤æ€§ | ä½ | é«˜ | â¬†ï¸ æå‡ |

## ğŸ”§ æ ¸å¿ƒ API

### `cluster_with_stats()`

ç»Ÿä¸€çš„èšç±»æ¥å£ï¼Œæ”¯æŒæ‰€æœ‰èšç±»ç®—æ³•ï¼š

```python
from utils.cluster.cluster_algorithms import cluster_with_stats

# åŸºæœ¬ç”¨æ³•
labels, stats = cluster_with_stats(
    embedding_matrix=embeddings,
    method="hdbscan",  # æˆ– "kmeans", "agglomerative", "spectral"
    min_cluster_size=2,
    metric="cosine"
)

# è‡ªåŠ¨æ‰“å°ç»Ÿè®¡ä¿¡æ¯
print(f"å‘ç° {stats['n_clusters']} ä¸ªç°‡")
print(f"å™ªå£°ç‚¹: {stats['n_noise']}")
```

**å‚æ•°è¯´æ˜:**
- `embedding_matrix`: (N, D) åµŒå…¥å‘é‡çŸ©é˜µ
- `method`: èšç±»æ–¹æ³•åç§°
  - `"hdbscan"`: å±‚æ¬¡å¯†åº¦èšç±»ï¼ˆè‡ªåŠ¨ç¡®å®šç°‡æ•°ï¼‰
  - `"kmeans"`: Kå‡å€¼èšç±»ï¼ˆéœ€è¦æŒ‡å®š kï¼‰
  - `"agglomerative"`: å±‚æ¬¡èšç±»ï¼ˆéœ€è¦æŒ‡å®šç°‡æ•°ï¼‰
  - `"spectral"`: è°±èšç±»ï¼ˆéœ€è¦æŒ‡å®šç°‡æ•°ï¼‰
- `**kwargs`: å„æ–¹æ³•ç‰¹å®šå‚æ•°

**è¿”å›å€¼:**
- `labels`: èšç±»æ ‡ç­¾æ•°ç»„ï¼Œ-1 è¡¨ç¤ºå™ªå£°ç‚¹
- `stats`: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
  - `n_clusters`: ç°‡æ•°é‡ï¼ˆä¸å«å™ªå£°ï¼‰
  - `n_noise`: å™ªå£°ç‚¹æ•°é‡
  - `cluster_sizes`: å„ç°‡å¤§å°åˆ—è¡¨
  - `largest_cluster`: æœ€å¤§ç°‡å¤§å°
  - `smallest_cluster`: æœ€å°ç°‡å¤§å°ï¼ˆä¸å«å™ªå£°ï¼‰
  - `avg_cluster_size`: å¹³å‡ç°‡å¤§å°

### `get_cluster_info()`

ä»èšç±»æ ‡ç­¾ä¸­æå–è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ï¼š

```python
from utils.cluster.cluster_algorithms import get_cluster_info

stats = get_cluster_info(labels)
```

## ğŸ“š æ”¯æŒçš„èšç±»ç®—æ³•

### 1. HDBSCAN (æ¨è)

**ä¼˜åŠ¿:**
- è‡ªåŠ¨ç¡®å®šç°‡æ•°é‡
- å¤„ç†ä¸è§„åˆ™å½¢çŠ¶çš„ç°‡
- æ”¯æŒå¯å˜å¯†åº¦çš„ç°‡
- è‡ªåŠ¨è¯†åˆ«å™ªå£°ç‚¹

**å‚æ•°:**
```python
labels, stats = cluster_with_stats(
    embedding_matrix,
    method="hdbscan",
    min_cluster_size=2,           # æœ€å°ç°‡å¤§å°
    metric="cosine",              # è·ç¦»åº¦é‡
    cluster_selection_method="eom" # 'eom' æˆ– 'leaf'
)
```

**EOM vs Leaf:**
- `eom` (Excess of Mass): æ›´ä¿å®ˆï¼Œé€‚åˆå¤§æ•°æ®é›†
- `leaf`: æ›´ç»†ç²’åº¦ï¼Œé€‚åˆå°ç°‡æ£€æµ‹

**æ³¨æ„äº‹é¡¹:**
- EOM åœ¨å°æ•°æ®é›†ï¼ˆ<100 æ ·æœ¬ï¼‰ä¸Šå¯èƒ½è¡¨ç°ä¸ä½³
- éœ€è¦è¶³å¤Ÿçš„æ ·æœ¬æ¥å»ºç«‹ç¨³å®šçš„å¯†åº¦åˆ†å¸ƒ

### 2. K-Means

**ä¼˜åŠ¿:**
- å¿«é€Ÿé«˜æ•ˆ
- é€‚åˆçƒå½¢ç°‡
- ç»“æœç¨³å®š

**å‚æ•°:**
```python
labels, stats = cluster_with_stats(
    embedding_matrix,
    method="kmeans",
    n_clusters=450,      # ç°‡æ•°é‡
    random_state=42      # éšæœºç§å­
)
```

### 3. Agglomerative Clustering

**ä¼˜åŠ¿:**
- å±‚æ¬¡ç»“æ„æ¸…æ™°
- æ”¯æŒä½™å¼¦è·ç¦»
- é€‚åˆæ–‡æœ¬åµŒå…¥

**å‚æ•°:**
```python
labels, stats = cluster_with_stats(
    embedding_matrix,
    method="agglomerative",
    n_clusters=450,         # ç°‡æ•°é‡
    affinity="cosine",      # è·ç¦»åº¦é‡
    linkage="average"       # é“¾æ¥æ–¹å¼
)
```

**å‚æ•°è¯´æ˜:**
- `affinity`: è·ç¦»åº¦é‡æ–¹å¼
  - `"cosine"`: ä½™å¼¦è·ç¦»ï¼ˆæ¨èç”¨äºæ–‡æœ¬ï¼‰
  - `"euclidean"`: æ¬§æ°è·ç¦»
  - `"manhattan"`: æ›¼å“ˆé¡¿è·ç¦»
- `linkage`: ç°‡é—´è·ç¦»è®¡ç®—æ–¹å¼
  - `"average"`: å¹³å‡é“¾æ¥ï¼ˆæ¨èä¸ cosine æ­é…ï¼‰
  - `"complete"`: å®Œå…¨é“¾æ¥
  - `"single"`: å•é“¾æ¥

**æœ€ä½³å®è·µ:**
å¯¹äºæ–‡æœ¬åµŒå…¥ï¼Œæ¨èä½¿ç”¨ `affinity="cosine"` å’Œ `linkage="average"`

### 4. Spectral Clustering

**ä¼˜åŠ¿:**
- å¤„ç†éå‡¸ç°‡
- åŸºäºå›¾ç†è®º
- é€‚åˆå¤æ‚æ‹“æ‰‘ç»“æ„

**å‚æ•°:**
```python
labels, stats = cluster_with_stats(
    embedding_matrix,
    method="spectral",
    n_clusters=450,       # ç°‡æ•°é‡
    n_neighbors=15,       # KNN é‚»å±…æ•°
    random_state=42
)
```

**æ³¨æ„äº‹é¡¹:**
- `n_neighbors` å¿…é¡» <= æ ·æœ¬æ•°
- è‡ªåŠ¨è°ƒæ•´æœºåˆ¶ä¼šåœ¨æ ·æœ¬æ•°ä¸è¶³æ—¶ç»™å‡ºè­¦å‘Š

## ğŸ”¬ å›¾èšç±»ç®—æ³•

é™¤äº†å‘é‡èšç±»ï¼Œè¿˜æ”¯æŒåŸºäºå›¾çš„èšç±»æ–¹æ³•ï¼ˆä½äº `utils/cluster/graph_clustering.py`ï¼‰ï¼š

### é˜ˆå€¼èšç±»ï¼ˆThreshold Clusteringï¼‰

```python
from utils.cluster.graph_clustering import graph_threshold_clustering

clusters = graph_threshold_clustering(
    embedding_matrix=embeddings,
    ids=sample_ids,
    similarity_threshold=0.85,
    use_cosine=True
)
```

**è¿”å›æ ¼å¼:** `{canonical_id: [member_ids]}`

### K-Core èšç±»

```python
from utils.cluster.graph_clustering import graph_kcore_clustering

clusters = graph_kcore_clustering(
    embedding_matrix=embeddings,
    ids=sample_ids,
    similarity_threshold=0.85,
    k_core=15,
    use_cosine=True
)
```

**å·¥ä½œåŸç†:**
1. æ„å»ºç›¸ä¼¼åº¦å›¾ï¼ˆè¾¹ = ç›¸ä¼¼åº¦ >= é˜ˆå€¼ï¼‰
2. æå– k-core å­å›¾ï¼ˆèŠ‚ç‚¹åº¦ >= k_coreï¼‰
3. åœ¨ k-core ä¸­æ‰¾è¿é€šåˆ†é‡ä½œä¸ºç°‡

## ğŸ“Š ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬å·¥ä½œæµ

```python
from utils.cluster.cluster_algorithms import cluster_with_stats
import numpy as np

# å‡†å¤‡æ•°æ®
embeddings = np.random.randn(2000, 1536)  # 2000 ä¸ªåˆ›æ–°ï¼Œ1536 ç»´åµŒå…¥

# è¿è¡Œèšç±»
labels, stats = cluster_with_stats(
    embedding_matrix=embeddings,
    method="hdbscan",
    min_cluster_size=2,
    metric="cosine"
)

# æŸ¥çœ‹ç»“æœ
print(f"æ€»æ ·æœ¬æ•°: {len(labels)}")
print(f"å‘ç°ç°‡æ•°: {stats['n_clusters']}")
print(f"å™ªå£°ç‚¹æ•°: {stats['n_noise']}")
print(f"æœ€å¤§ç°‡å¤§å°: {stats['largest_cluster']}")
print(f"å¹³å‡ç°‡å¤§å°: {stats['avg_cluster_size']:.2f}")
```

### åœ¨ innovation_resolution.py ä¸­çš„åº”ç”¨

```python
# æ—§ä»£ç ï¼š50+ è¡Œ if-elif
if method_lower == "hdbscan":
    min_cluster_size = method_kwargs.get("min_cluster_size", 2)
    # ... æ›´å¤šå‚æ•° ...
    labels = cluster_hdbscan(...)
elif method_lower == "kmeans":
    # ... é‡å¤çš„ä»£ç  ...

# æ–°ä»£ç ï¼š15 è¡Œç»Ÿä¸€æ¥å£
labels, stats = cluster_with_stats(
    embedding_matrix=embedding_matrix,
    method=method_lower,
    **method_kwargs
)

print(f"\nèšç±»ç»Ÿè®¡:")
print(f"  ç°‡æ•°é‡: {stats['n_clusters']}")
print(f"  å™ªå£°ç‚¹: {stats['n_noise']}")
print(f"  æœ€å¤§ç°‡: {stats['largest_cluster']}")
print(f"  å¹³å‡ç°‡å¤§å°: {stats['avg_cluster_size']:.2f}")
```

## ğŸ§ª æµ‹è¯•

è¿è¡Œèšç±»æµ‹è¯•å¥—ä»¶ï¼š

```bash
python tests/test_cluster.py
```

**æµ‹è¯•è¦†ç›–:**
- âœ… 4 ç§å¹³é¢èšç±»ç®—æ³•ï¼ˆHDBSCAN, K-Means, Agglomerative, Spectralï¼‰
- âœ… 2 ç§å›¾èšç±»ç®—æ³•ï¼ˆThreshold, K-Coreï¼‰
- âœ… ç»Ÿè®¡å‡½æ•°åœ¨å„ç§åœºæ™¯ä¸‹çš„è¡¨ç°
- âœ… è¾¹ç•Œæƒ…å†µå¤„ç†ï¼ˆå°æ•°æ®é›†ã€n_neighbors è°ƒæ•´ç­‰ï¼‰

## ğŸ“ˆ æ€§èƒ½åŸºå‡†

åœ¨ ~2000 ä¸ªåˆ›æ–°æ ·æœ¬ä¸Šçš„è¡¨ç°ï¼š

| æ–¹æ³• | åˆ›æ–°æ•°é‡ | ç»„ç»‡æ•°é‡ | å…³ç³»æ•°é‡ | ç‰¹ç‚¹ |
|------|---------|---------|---------|------|
| é˜ˆå€¼èšç±» | 1911 | 2490 | 12502 | åŸºå‡†æ–¹æ³• |
| HDBSCAN | 1735 | 2490 | 12341 | æœ€ä¿å®ˆ |
| K-Means | 1911 | 2490 | 12544 | ç¨³å®š |
| Agglomerative | 1911 | 2490 | 12544 | å±‚æ¬¡æ¸…æ™° |
| Spectral | 1911 | 2490 | 12612 | é€‚åˆå¤æ‚ç»“æ„ |

## ğŸ”§ æ•°å­¦åŸç†

### ä½™å¼¦è·ç¦»çš„å½’ä¸€åŒ–æŠ€å·§

åœ¨èšç±»ä¸­ä½¿ç”¨ä½™å¼¦è·ç¦»æ—¶ï¼Œæœ‰ä¸€ä¸ªå·§å¦™çš„æ•°å­¦ç­‰ä»·ï¼š

```python
# L2 å½’ä¸€åŒ– + æ¬§æ°è·ç¦» â‰ˆ ä½™å¼¦è·ç¦»
normalized_X = normalize(X, norm='l2')
euclidean_distance(normalized_X) âˆ cosine_distance(X)
```

**æ•°å­¦æ¨å¯¼:**

$$
d_{euclidean}(\mathbf{u}, \mathbf{v}) = \sqrt{2 \times (1 - \cos(\mathbf{u}, \mathbf{v}))}
$$

å…¶ä¸­ $\mathbf{u}, \mathbf{v}$ æ˜¯ L2 å½’ä¸€åŒ–åçš„å‘é‡ã€‚

**å®é™…åº”ç”¨:**
```python
# Agglomerative clustering ä¸­çš„å®ç°
if affinity == "cosine":
    X_normalized = normalize(X, norm='l2')
    model = AgglomerativeClustering(
        n_clusters=n_clusters,
        affinity='euclidean',  # åœ¨å½’ä¸€åŒ–æ•°æ®ä¸Šä½¿ç”¨æ¬§æ°è·ç¦»
        linkage=linkage
    )
    labels = model.fit_predict(X_normalized)
```

è¿™ä¸ªæŠ€å·§ä½¿å¾—å¯ä»¥åœ¨åªæ”¯æŒæ¬§æ°è·ç¦»çš„ç®—æ³•ä¸­ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ã€‚

## ğŸš€ æ‰©å±•æŒ‡å—

### æ·»åŠ æ–°çš„èšç±»æ–¹æ³•

1. åœ¨ `utils/cluster/cluster_algorithms.py` ä¸­å®ç°æ–°æ–¹æ³•ï¼š

```python
def cluster_new_method(
    embedding_matrix: np.ndarray,
    param1: int = 10,
    param2: str = "default"
) -> np.ndarray:
    """
    æ–°çš„èšç±»æ–¹æ³•å®ç°
    
    Args:
        embedding_matrix: åµŒå…¥å‘é‡çŸ©é˜µ
        param1: å‚æ•°1è¯´æ˜
        param2: å‚æ•°2è¯´æ˜
        
    Returns:
        labels: èšç±»æ ‡ç­¾æ•°ç»„
    """
    # å®ç°ä½ çš„èšç±»é€»è¾‘
    labels = ...
    return labels
```

2. åœ¨ `cluster_with_stats()` ä¸­æ·»åŠ æ–°æ–¹æ³•çš„åˆ†æ”¯ï¼š

```python
def cluster_with_stats(...):
    # ...
    elif method == "new_method":
        param1 = kwargs.get("param1", 10)
        param2 = kwargs.get("param2", "default")
        labels = cluster_new_method(
            embedding_matrix=embedding_matrix,
            param1=param1,
            param2=param2
        )
```

3. åœ¨ `tests/test_cluster.py` ä¸­æ·»åŠ æµ‹è¯•

## ğŸ“ æœ€ä½³å®è·µ

1. **é€‰æ‹©åˆé€‚çš„èšç±»æ–¹æ³•:**
   - ä¸çŸ¥é“ç°‡æ•° â†’ HDBSCAN
   - çŸ¥é“ç°‡æ•° + çƒå½¢ç°‡ â†’ K-Means
   - æ–‡æœ¬åµŒå…¥ + å±‚æ¬¡ç»“æ„ â†’ Agglomerative
   - å¤æ‚æ‹“æ‰‘ â†’ Spectral

2. **å‚æ•°è°ƒä¼˜:**
   - HDBSCAN: ä» `min_cluster_size=2` å¼€å§‹ï¼Œæ ¹æ®å™ªå£°æ¯”ä¾‹è°ƒæ•´
   - K-Means: ä½¿ç”¨è‚˜éƒ¨æ³•åˆ™ç¡®å®š k
   - Agglomerative: æ–‡æœ¬ç”¨ `affinity="cosine"`
   - Spectral: ç¡®ä¿ `n_neighbors < n_samples`

3. **æ•°æ®é¢„å¤„ç†:**
   - å¯¹äºæ–‡æœ¬åµŒå…¥ï¼Œè€ƒè™‘ L2 å½’ä¸€åŒ–
   - æ£€æŸ¥åµŒå…¥è´¨é‡ï¼ˆé¿å…å…¨é›¶å‘é‡ï¼‰
   - å¤§æ•°æ®é›†è€ƒè™‘é™ç»´ï¼ˆPCA, UMAPï¼‰

4. **ç»“æœéªŒè¯:**
   - æ£€æŸ¥ `stats` ä¸­çš„å™ªå£°æ¯”ä¾‹
   - å¯è§†åŒ–ç°‡çš„åˆ†å¸ƒ
   - äººå·¥æŠ½æ ·éªŒè¯åˆå¹¶è´¨é‡

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [å¼€å‘æŒ‡å—](DEVELOPMENT.md)
- [å¿«é€Ÿå¼€å§‹](GETTING_STARTED.md)
- [æµ‹è¯•è¯´æ˜](../tests/README.md)

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®æ–°çš„èšç±»ç®—æ³•æˆ–æ”¹è¿›ç°æœ‰å®ç°ï¼

---

**æœ€åæ›´æ–°:** 2025å¹´10æœˆ17æ—¥
