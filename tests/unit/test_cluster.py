# tests/test_cluster.py
# å…¨é¢æµ‹è¯•æ‰€æœ‰èšç±»ç®—æ³•

import numpy as np
import sys
from pathlib import Path

PROJECT_ROOT = Path(__file__).resolve().parents[2]
SRC_DIR = PROJECT_ROOT / "src"
if str(SRC_DIR) not in sys.path:
    sys.path.insert(0, str(SRC_DIR))

from innovation_platform.utils.cluster.cluster_algorithms import cluster_with_stats, get_cluster_info
from innovation_platform.utils.cluster.graph_clustering import graph_threshold_clustering, graph_kcore_clustering


def create_test_data():
    """åˆ›å»ºæµ‹è¯•æ•°æ®ï¼š4 ä¸ªæ ·æœ¬ï¼Œ2 ä¸ªæ˜æ˜¾çš„ç°‡"""
    # ç°‡ 1: A å’Œ B å¾ˆç›¸ä¼¼
    # ç°‡ 2: C å’Œ D å¾ˆç›¸ä¼¼
    X = np.array([
        [0.1, 0.1, 0.2],      # A
        [0.15, 0.05, 0.25],   # B (ä¸ A ç›¸ä¼¼)
        [0.9, 0.8, 0.75],     # C
        [0.85, 0.78, 0.7]     # D (ä¸ C ç›¸ä¼¼)
    ])
    ids = ["A", "B", "C", "D"]
    return X, ids


def test_flat_clustering_methods():
    """æµ‹è¯•æ‰€æœ‰å¹³é¢èšç±»ç®—æ³•"""
    print("=" * 70)
    print("ğŸ§ª æµ‹è¯•å¹³é¢èšç±»ç®—æ³•ï¼ˆHDBSCAN, K-Means, Agglomerative, Spectralï¼‰")
    print("=" * 70)
    
    X, ids = create_test_data()
    
    # æµ‹è¯•é…ç½®
    methods = [
        {'name': 'HDBSCAN', 'method': 'hdbscan', 'kwargs': {'min_cluster_size': 2, 'metric': 'cosine'}},
        {'name': 'K-Means', 'method': 'kmeans', 'kwargs': {'n_clusters': 2, 'random_state': 42}},
        {'name': 'Agglomerative', 'method': 'agglomerative', 'kwargs': {'n_clusters': 2, 'affinity': 'cosine'}},
        {'name': 'Spectral', 'method': 'spectral', 'kwargs': {'n_clusters': 2, 'affinity': 'nearest_neighbors', 'n_neighbors': 2}},
    ]
    
    results = []
    
    for config in methods:
        print(f"\nğŸ“Œ æµ‹è¯• {config['name']}")
        print("-" * 70)
        
        try:
            # ä½¿ç”¨ç»Ÿä¸€æ¥å£
            labels, stats = cluster_with_stats(X, method=config['method'], **config['kwargs'])
            
            # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
            print(f"âœ… èšç±»æˆåŠŸï¼")
            print(f"   æ–¹æ³•: {stats['method'].upper()}")
            print(f"   ç°‡æ•°é‡: {stats['n_clusters']}")
            print(f"   å™ªéŸ³ç‚¹: {stats['n_noise']}")
            print(f"   æœ€å¤§ç°‡å¤§å°: {stats['largest_cluster']}")
            print(f"   æœ€å°ç°‡å¤§å°: {stats['smallest_cluster']}")
            print(f"   æ€»æ ·æœ¬æ•°: {stats['total_samples']}")
            
            # æ˜¾ç¤ºæ¯ä¸ªæ ·æœ¬çš„æ ‡ç­¾
            print(f"   æ ‡ç­¾åˆ†é…: ", end="")
            for i, (id_name, label) in enumerate(zip(ids, labels)):
                print(f"{id_name}â†’{label}", end="  ")
            print()
            
            # ä¿å­˜ç»“æœ
            results.append({
                'method': config['name'],
                'success': True,
                'stats': stats,
                'labels': labels
            })
            
        except Exception as e:
            print(f"âŒ å¤±è´¥: {str(e)}")
            results.append({
                'method': config['name'],
                'success': False,
                'error': str(e)
            })
    
    return results


def test_graph_clustering_methods():
    """æµ‹è¯•å›¾èšç±»ç®—æ³•"""
    print("\n\n" + "=" * 70)
    print("ğŸ§ª æµ‹è¯•å›¾èšç±»ç®—æ³•ï¼ˆThreshold-based, K-Coreï¼‰")
    print("=" * 70)
    
    X, ids = create_test_data()
    
    # æµ‹è¯• 1: Threshold-based clustering
    print(f"\nğŸ“Œ æµ‹è¯• Threshold-based Clustering")
    print("-" * 70)
    try:
        clusters_dict = graph_threshold_clustering(
            embedding_matrix=X,
            ids=ids,
            similarity_threshold=0.9,
            use_cosine=True
        )
        print(f"âœ… æˆåŠŸï¼æ‰¾åˆ° {len(clusters_dict)} ä¸ªç°‡")
        for canonical, members in clusters_dict.items():
            print(f"   ç°‡ {canonical}: {members}")
    except Exception as e:
        print(f"âŒ å¤±è´¥: {str(e)}")
    
    # æµ‹è¯• 2: K-Core clustering
    print(f"\nğŸ“Œ æµ‹è¯• K-Core Clustering")
    print("-" * 70)
    try:
        clusters_dict = graph_kcore_clustering(
            embedding_matrix=X,
            ids=ids,
            similarity_threshold=0.85,
            k_core=1,  # ä½é˜ˆå€¼ä»¥ç¡®ä¿æœ‰ç»“æœ
            use_cosine=True
        )
        print(f"âœ… æˆåŠŸï¼æ‰¾åˆ° {len(clusters_dict)} ä¸ªç°‡")
        for canonical, members in clusters_dict.items():
            print(f"   ç°‡ {canonical}: {members}")
    except Exception as e:
        print(f"âŒ å¤±è´¥: {str(e)}")


def test_get_cluster_info():
    """æµ‹è¯• get_cluster_info å‡½æ•°"""
    print("\n\n" + "=" * 70)
    print("ğŸ§ª æµ‹è¯• get_cluster_info() å‡½æ•°")
    print("=" * 70)
    
    # æ¨¡æ‹Ÿä¸åŒçš„æ ‡ç­¾åœºæ™¯
    test_cases = [
        {
            'name': 'æ­£å¸¸èšç±»ï¼ˆæ— å™ªéŸ³ï¼‰',
            'labels': np.array([0, 0, 1, 1, 2, 2, 2])
        },
        {
            'name': 'HDBSCAN èšç±»ï¼ˆæœ‰å™ªéŸ³ç‚¹ï¼‰',
            'labels': np.array([0, 0, 1, -1, 2, 2, -1])
        },
        {
            'name': 'æç«¯æƒ…å†µï¼ˆå…¨éƒ¨å™ªéŸ³ï¼‰',
            'labels': np.array([-1, -1, -1, -1])
        },
        {
            'name': 'æç«¯æƒ…å†µï¼ˆå…¨éƒ¨åŒä¸€ç°‡ï¼‰',
            'labels': np.array([0, 0, 0, 0, 0])
        }
    ]
    
    for test_case in test_cases:
        print(f"\nğŸ“Œ {test_case['name']}")
        print(f"   æ ‡ç­¾: {test_case['labels']}")
        
        stats = get_cluster_info(test_case['labels'])
        
        print(f"   ğŸ“Š ç»Ÿè®¡ç»“æœ:")
        print(f"      ç°‡æ•°é‡: {stats['n_clusters']}")
        print(f"      å™ªéŸ³ç‚¹: {stats['n_noise']}")
        print(f"      æœ€å¤§ç°‡: {stats['largest_cluster']}")
        print(f"      æœ€å°ç°‡: {stats['smallest_cluster']}")
        print(f"      æ€»æ ·æœ¬: {stats['total_samples']}")
        if stats['cluster_sizes']:
            print(f"      ç°‡å¤§å°åˆ†å¸ƒ: {stats['cluster_sizes']}")


def run_comparison_test():
    """æ¯”è¾ƒæ‰€æœ‰æ–¹æ³•çš„æ€§èƒ½"""
    print("\n\n" + "=" * 70)
    print("ğŸ“Š èšç±»æ–¹æ³•å¯¹æ¯”æ€»ç»“")
    print("=" * 70)
    
    X, ids = create_test_data()
    
    methods = ['hdbscan', 'kmeans', 'agglomerative', 'spectral']
    
    print(f"\n{'æ–¹æ³•':<15} {'ç°‡æ•°':<8} {'å™ªéŸ³ç‚¹':<10} {'æœ€å¤§ç°‡':<10} {'æœ€å°ç°‡':<10}")
    print("-" * 70)
    
    for method in methods:
        try:
            if method == 'hdbscan':
                kwargs = {'min_cluster_size': 2, 'metric': 'cosine'}
            elif method == 'spectral':
                # Spectral éœ€è¦ n_neighbors < æ ·æœ¬æ•° (è¿™é‡Œæ˜¯ 4)
                kwargs = {'n_clusters': 2, 'n_neighbors': 2}
            else:
                kwargs = {'n_clusters': 2}
            
            labels, stats = cluster_with_stats(X, method=method, **kwargs)
            
            print(f"{method.upper():<15} {stats['n_clusters']:<8} {stats['n_noise']:<10} "
                  f"{stats['largest_cluster']:<10} {stats['smallest_cluster']:<10}")
        except Exception as e:
            print(f"{method.upper():<15} {'ERROR':<8} {str(e)[:40]}")


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n")
    print("ğŸš€ å¼€å§‹èšç±»ç®—æ³•æµ‹è¯•å¥—ä»¶")
    print("=" * 70)
    
    # æµ‹è¯• 1: å¹³é¢èšç±»
    test_flat_clustering_methods()
    
    # æµ‹è¯• 2: å›¾èšç±»
    test_graph_clustering_methods()
    
    # æµ‹è¯• 3: ç»Ÿè®¡å‡½æ•°
    test_get_cluster_info()
    
    # æµ‹è¯• 4: å¯¹æ¯”åˆ†æ
    run_comparison_test()
    
    print("\n\n" + "=" * 70)
    print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("=" * 70)


if __name__ == "__main__":
    main()
