#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Network Analysis Module

This module provides structured components for analyzing innovation networks,
including statistics calculation, centrality analysis, and key node identification.
"""

from typing import Dict, List, Tuple, Optional
import networkx as nx


class NetworkGraphBuilder:
    """æ„å»º NetworkX å›¾å¯¹è±¡"""
    
    @staticmethod
    def build(consolidated_graph: Dict) -> nx.Graph:
        """
        ä»åˆå¹¶çš„çŸ¥è¯†å›¾è°±æ„å»º NetworkX å›¾
        
        Args:
            consolidated_graph: åˆå¹¶åçš„çŸ¥è¯†å›¾è°±
            
        Returns:
            nx.Graph: NetworkX å›¾å¯¹è±¡
        """
        G = nx.Graph()
        
        # æ·»åŠ åˆ›æ–°èŠ‚ç‚¹
        for innovation_id, innovation in consolidated_graph['innovations'].items():
            G.add_node(
                innovation_id,
                type='Innovation',
                names=', '.join(innovation['names']),
                sources=len(innovation['sources']),
                developed_by=len(innovation['developed_by'])
            )
        
        # æ·»åŠ ç»„ç»‡èŠ‚ç‚¹
        for org_id, org in consolidated_graph['organizations'].items():
            G.add_node(
                org_id,
                type='Organization',
                name=org['name']
            )
        
        # æ·»åŠ è¾¹
        for rel in consolidated_graph['relationships']:
            G.add_edge(rel['source'], rel['target'], type=rel['type'])
        
        return G


class InnovationStatisticsCalculator:
    """è®¡ç®—åˆ›æ–°ç½‘ç»œçš„åŸºç¡€ç»Ÿè®¡æŒ‡æ ‡"""
    
    @staticmethod
    def calculate(consolidated_graph: Dict) -> Dict:
        """
        è®¡ç®—åˆ›æ–°ç½‘ç»œçš„åŸºç¡€ç»Ÿè®¡æŒ‡æ ‡
        
        Args:
            consolidated_graph: åˆå¹¶åçš„çŸ¥è¯†å›¾è°±
            
        Returns:
            Dict: ç»Ÿè®¡æŒ‡æ ‡å­—å…¸
        """
        innovations = consolidated_graph['innovations']
        
        if not innovations:
            return {
                'total': 0,
                'avg_sources': 0,
                'avg_developers': 0,
                'multi_source_count': 0,
                'multi_developer_count': 0
            }
        
        total_innovations = len(innovations)
        
        # è®¡ç®—å¹³å‡æ•°æ®æºæ•°
        total_sources = sum(len(i['sources']) for i in innovations.values())
        avg_sources = total_sources / total_innovations
        
        # è®¡ç®—å¹³å‡å¼€å‘è€…æ•°
        total_developers = sum(len(i['developed_by']) for i in innovations.values())
        avg_developers = total_developers / total_innovations
        
        # è®¡ç®—å¤šæºåˆ›æ–°æ•°é‡
        multi_source_count = sum(
            1 for i in innovations.values() if len(i['sources']) > 1
        )
        
        # è®¡ç®—å¤šå¼€å‘è€…åˆ›æ–°æ•°é‡
        multi_developer_count = sum(
            1 for i in innovations.values() if len(i['developed_by']) > 1
        )
        
        return {
            'total': total_innovations,
            'avg_sources': avg_sources,
            'avg_developers': avg_developers,
            'multi_source_count': multi_source_count,
            'multi_developer_count': multi_developer_count
        }


class MultiSourceInnovationExtractor:
    """æå–å¤šæ•°æ®æºéªŒè¯çš„åˆ›æ–°"""
    
    @staticmethod
    def extract(consolidated_graph: Dict) -> Dict:
        """
        æå–åœ¨å¤šä¸ªæ•°æ®æºä¸­éƒ½å‡ºç°çš„åˆ›æ–°
        
        Args:
            consolidated_graph: åˆå¹¶åçš„çŸ¥è¯†å›¾è°±
            
        Returns:
            Dict: å¤šæºåˆ›æ–°å­—å…¸
        """
        return {
            innovation_id: innovation_data
            for innovation_id, innovation_data in consolidated_graph['innovations'].items()
            if len(innovation_data['sources']) > 1
        }


class OrganizationRanker:
    """ç»„ç»‡æ’åºå™¨ - æŒ‰åˆ›æ–°æ•°é‡æ’åº"""
    
    @staticmethod
    def rank_by_innovation_count(
        consolidated_graph: Dict,
        top_n: int = 10
    ) -> List[Tuple[str, int]]:
        """
        æŒ‰åˆ›æ–°æ•°é‡å¯¹ç»„ç»‡æ’åº
        
        Args:
            consolidated_graph: åˆå¹¶åçš„çŸ¥è¯†å›¾è°±
            top_n: è¿”å›å‰ N ä¸ªç»„ç»‡
            
        Returns:
            List[Tuple[str, int]]: (ç»„ç»‡ID, åˆ›æ–°æ•°é‡) åˆ—è¡¨
        """
        org_innovation_counts = {}
        
        # ç»Ÿè®¡æ¯ä¸ªç»„ç»‡çš„åˆ›æ–°æ•°é‡
        for rel in consolidated_graph['relationships']:
            if (rel['type'] == 'DEVELOPED_BY' and 
                rel['target'] in consolidated_graph['organizations']):
                org_id = rel['target']
                org_innovation_counts[org_id] = org_innovation_counts.get(org_id, 0) + 1
        
        # æ’åºå¹¶è¿”å› Top N
        sorted_orgs = sorted(
            org_innovation_counts.items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        return sorted_orgs[:top_n]


class CentralityAnalyzer:
    """ä¸­å¿ƒæ€§åˆ†æå™¨ - åˆ†æç½‘ç»œä¸­çš„å…³é”®èŠ‚ç‚¹"""
    
    def __init__(self, graph: nx.Graph):
        """
        åˆå§‹åŒ–ä¸­å¿ƒæ€§åˆ†æå™¨
        
        Args:
            graph: NetworkX å›¾å¯¹è±¡
        """
        self.graph = graph
        self.betweenness_centrality = None
        self.eigenvector_centrality = None
    
    def compute_centralities(self, max_iter: int = 1000) -> bool:
        """
        è®¡ç®—ä¸­å¿ƒæ€§æŒ‡æ ‡
        
        Args:
            max_iter: ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§çš„æœ€å¤§è¿­ä»£æ¬¡æ•°
            
        Returns:
            bool: æ˜¯å¦è®¡ç®—æˆåŠŸ
        """
        try:
            # è®¡ç®—ä»‹æ•°ä¸­å¿ƒæ€§ï¼ˆè¡¡é‡èŠ‚ç‚¹çš„ä¸­ä»‹ä½œç”¨ï¼‰
            self.betweenness_centrality = nx.betweenness_centrality(self.graph)
            
            # è®¡ç®—ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§ï¼ˆè¡¡é‡èŠ‚ç‚¹è¿æ¥çš„è´¨é‡ï¼‰
            self.eigenvector_centrality = nx.eigenvector_centrality(
                self.graph,
                max_iter=max_iter
            )
            
            return True
        except Exception as e:
            print(f"Warning: Centrality computation failed: {e}")
            return False
    
    def get_key_organizations(self, top_n: int = 10) -> List[Tuple[str, float]]:
        """
        è·å–å…³é”®ç»„ç»‡ï¼ˆåŸºäºä»‹æ•°ä¸­å¿ƒæ€§ï¼‰
        
        Args:
            top_n: è¿”å›å‰ N ä¸ªç»„ç»‡
            
        Returns:
            List[Tuple[str, float]]: (ç»„ç»‡ID, ä¸­å¿ƒæ€§å¾—åˆ†) åˆ—è¡¨
        """
        if self.betweenness_centrality is None:
            return []
        
        # ç­›é€‰ç»„ç»‡èŠ‚ç‚¹
        org_centralities = [
            (node, self.betweenness_centrality[node])
            for node in self.graph.nodes
            if self.graph.nodes[node].get('type') == 'Organization'
        ]
        
        # æ’åºå¹¶è¿”å› Top N
        sorted_orgs = sorted(
            org_centralities,
            key=lambda x: x[1],
            reverse=True
        )
        
        return sorted_orgs[:top_n]
    
    def get_key_innovations(self, top_n: int = 10) -> List[Tuple[str, float]]:
        """
        è·å–å…³é”®åˆ›æ–°ï¼ˆåŸºäºç‰¹å¾å‘é‡ä¸­å¿ƒæ€§ï¼‰
        
        Args:
            top_n: è¿”å›å‰ N ä¸ªåˆ›æ–°
            
        Returns:
            List[Tuple[str, float]]: (åˆ›æ–°ID, ä¸­å¿ƒæ€§å¾—åˆ†) åˆ—è¡¨
        """
        if self.eigenvector_centrality is None:
            return []
        
        # ç­›é€‰åˆ›æ–°èŠ‚ç‚¹
        innovation_centralities = [
            (node, self.eigenvector_centrality[node])
            for node in self.graph.nodes
            if self.graph.nodes[node].get('type') == 'Innovation'
        ]
        
        # æ’åºå¹¶è¿”å› Top N
        sorted_innovations = sorted(
            innovation_centralities,
            key=lambda x: x[1],
            reverse=True
        )
        
        return sorted_innovations[:top_n]


class InnovationNetworkAnalyzer:
    """åˆ›æ–°ç½‘ç»œåˆ†æå™¨ - åè°ƒæ‰€æœ‰åˆ†æç»„ä»¶"""
    
    def __init__(self, consolidated_graph: Dict):
        """
        åˆå§‹åŒ–ç½‘ç»œåˆ†æå™¨
        
        Args:
            consolidated_graph: åˆå¹¶åçš„çŸ¥è¯†å›¾è°±
        """
        self.consolidated_graph = consolidated_graph
        self.graph = None
        self.centrality_analyzer = None
    
    def analyze(
        self,
        top_n: int = 10,
        max_iter: int = 1000
    ) -> Dict:
        """
        æ‰§è¡Œå®Œæ•´çš„ç½‘ç»œåˆ†æ
        
        Args:
            top_n: è¿”å›å‰ N ä¸ªå…³é”®èŠ‚ç‚¹
            max_iter: ä¸­å¿ƒæ€§è®¡ç®—çš„æœ€å¤§è¿­ä»£æ¬¡æ•°
            
        Returns:
            Dict: åˆ†æç»“æœå­—å…¸
        """
        print("Analyzing innovation network...")
        
        # Step 1: æ„å»º NetworkX å›¾
        self.graph = NetworkGraphBuilder.build(self.consolidated_graph)
        
        # Step 2: è®¡ç®—åŸºç¡€ç»Ÿè®¡æŒ‡æ ‡
        stats = InnovationStatisticsCalculator.calculate(self.consolidated_graph)
        
        # Step 3: æå–å¤šæºåˆ›æ–°
        multi_source = MultiSourceInnovationExtractor.extract(self.consolidated_graph)
        
        # Step 4: æŒ‰åˆ›æ–°æ•°é‡æ’åºç»„ç»‡
        top_orgs = OrganizationRanker.rank_by_innovation_count(
            self.consolidated_graph,
            top_n=top_n
        )
        
        # Step 5: ä¸­å¿ƒæ€§åˆ†æ
        self.centrality_analyzer = CentralityAnalyzer(self.graph)
        centrality_success = self.centrality_analyzer.compute_centralities(max_iter=max_iter)
        
        if centrality_success:
            key_orgs = self.centrality_analyzer.get_key_organizations(top_n=top_n)
            key_innovations = self.centrality_analyzer.get_key_innovations(top_n=top_n)
        else:
            key_orgs = []
            key_innovations = []
        
        # è¿”å›åˆ†æç»“æœ
        return {
            'graph': self.graph,
            'stats': stats,
            'multi_source': multi_source,
            'top_orgs': top_orgs,
            'key_orgs': key_orgs,
            'key_innovations': key_innovations
        }
    
    def print_summary(self, analysis_results: Dict):
        """
        æ‰“å°åˆ†æç»“æœæ‘˜è¦
        
        Args:
            analysis_results: åˆ†æç»“æœå­—å…¸
        """
        stats = analysis_results['stats']
        
        print("\n" + "="*60)
        print("åˆ›æ–°ç½‘ç»œåˆ†ææ‘˜è¦")
        print("="*60)
        
        print(f"\nğŸ“Š åŸºç¡€ç»Ÿè®¡:")
        print(f"  - åˆ›æ–°æ€»æ•°: {stats['total']}")
        print(f"  - å¹³å‡æ•°æ®æºæ•°: {stats['avg_sources']:.2f}")
        print(f"  - å¹³å‡å¼€å‘è€…æ•°: {stats['avg_developers']:.2f}")
        print(f"  - å¤šæºéªŒè¯åˆ›æ–°: {stats['multi_source_count']}")
        print(f"  - åä½œåˆ›æ–°: {stats['multi_developer_count']}")
        
        print(f"\nğŸ¢ Top 5 æœ€æ´»è·ƒç»„ç»‡:")
        for i, (org_id, count) in enumerate(analysis_results['top_orgs'][:5], 1):
            org_name = self.consolidated_graph['organizations'].get(org_id, {}).get('name', org_id)
            print(f"  {i}. {org_name}: {count} ä¸ªåˆ›æ–°")
        
        if analysis_results['key_orgs']:
            print(f"\nâ­ Top 5 å…³é”®ç»„ç»‡ (ä»‹æ•°ä¸­å¿ƒæ€§):")
            for i, (org_id, centrality) in enumerate(analysis_results['key_orgs'][:5], 1):
                org_name = self.consolidated_graph['organizations'].get(org_id, {}).get('name', org_id)
                print(f"  {i}. {org_name}: {centrality:.4f}")
        
        if analysis_results['key_innovations']:
            print(f"\nğŸš€ Top 5 å…³é”®åˆ›æ–° (ç‰¹å¾å‘é‡ä¸­å¿ƒæ€§):")
            for i, (inno_id, centrality) in enumerate(analysis_results['key_innovations'][:5], 1):
                inno_names = list(self.consolidated_graph['innovations'][inno_id]['names'])
                inno_name = inno_names[0] if inno_names else inno_id
                print(f"  {i}. {inno_name}: {centrality:.4f}")
        
        print("\n" + "="*60)


def analyze_innovation_network(
    consolidated_graph: Dict,
    top_n: int = 10,
    max_iter: int = 1000,
    print_summary: bool = True
) -> Dict:
    """
    åˆ†æåˆ›æ–°ç½‘ç»œçš„ä¾¿æ·å‡½æ•°
    
    Args:
        consolidated_graph: åˆå¹¶åçš„çŸ¥è¯†å›¾è°±
        top_n: è¿”å›å‰ N ä¸ªå…³é”®èŠ‚ç‚¹
        max_iter: ä¸­å¿ƒæ€§è®¡ç®—çš„æœ€å¤§è¿­ä»£æ¬¡æ•°
        print_summary: æ˜¯å¦æ‰“å°åˆ†ææ‘˜è¦
        
    Returns:
        Dict: åˆ†æç»“æœå­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µ:
            - graph: NetworkX å›¾å¯¹è±¡
            - stats: åŸºç¡€ç»Ÿè®¡æŒ‡æ ‡
            - multi_source: å¤šæºéªŒè¯çš„åˆ›æ–°
            - top_orgs: Top N æœ€æ´»è·ƒç»„ç»‡
            - key_orgs: Top N å…³é”®ç»„ç»‡ï¼ˆä»‹æ•°ä¸­å¿ƒæ€§ï¼‰
            - key_innovations: Top N å…³é”®åˆ›æ–°ï¼ˆç‰¹å¾å‘é‡ä¸­å¿ƒæ€§ï¼‰
    """
    analyzer = InnovationNetworkAnalyzer(consolidated_graph)
    results = analyzer.analyze(top_n=top_n, max_iter=max_iter)
    
    if print_summary:
        analyzer.print_summary(results)
    
    return results
