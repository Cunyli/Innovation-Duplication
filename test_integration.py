#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
æµ‹è¯•é›†æˆåçš„ load_and_combine_data å‡½æ•°

éªŒè¯æ–°çš„ GraphDocumentLoader å’Œ NodeMapper é›†æˆæ˜¯å¦å·¥ä½œæ­£å¸¸
"""

import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from innovation_resolution import load_and_combine_data


def test_load_and_combine_data():
    """æµ‹è¯•æ•°æ®åŠ è½½å’Œåˆå¹¶åŠŸèƒ½"""
    print("="*60)
    print("æµ‹è¯• load_and_combine_data() é›†æˆ")
    print("="*60)
    
    try:
        print("\nğŸš€ å¼€å§‹åŠ è½½æ•°æ®...")
        print("âš ï¸  æ³¨æ„: è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´\n")
        
        # è°ƒç”¨å‡½æ•°
        df_relationships, all_pred_entities, all_pred_relations = load_and_combine_data()
        
        print("\n" + "="*60)
        print("âœ… æ•°æ®åŠ è½½æˆåŠŸ!")
        print("="*60)
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"  - å…³ç³»è®°å½•æ•°: {len(df_relationships):,}")
        print(f"  - é¢„æµ‹å®ä½“æ•°: {len(all_pred_entities):,}")
        print(f"  - é¢„æµ‹å…³ç³»æ•°: {len(all_pred_relations):,}")
        
        # æ˜¾ç¤ºDataFrameä¿¡æ¯
        print(f"\nğŸ“‹ å…³ç³»DataFrameä¿¡æ¯:")
        print(f"  - åˆ—æ•°: {len(df_relationships.columns)}")
        print(f"  - æ•°æ®æºåˆ†å¸ƒ:")
        if 'data_source' in df_relationships.columns:
            print(df_relationships['data_source'].value_counts().to_string(header=False))
        
        # æ˜¾ç¤ºå®ä½“ç±»å‹åˆ†å¸ƒ
        if all_pred_entities:
            print(f"\nğŸ·ï¸  å®ä½“ç±»å‹åˆ†å¸ƒ:")
            entity_types = {}
            for entity in all_pred_entities:
                entity_type = entity.get('type', 'Unknown')
                entity_types[entity_type] = entity_types.get(entity_type, 0) + 1
            for entity_type, count in sorted(entity_types.items(), key=lambda x: x[1], reverse=True):
                print(f"  - {entity_type}: {count:,}")
        
        # æ˜¾ç¤ºå…³ç³»ç±»å‹åˆ†å¸ƒ
        if all_pred_relations:
            print(f"\nğŸ”— å…³ç³»ç±»å‹åˆ†å¸ƒ:")
            relation_types = {}
            for relation in all_pred_relations:
                relation_type = relation.get('relation', 'Unknown')
                relation_types[relation_type] = relation_types.get(relation_type, 0) + 1
            for relation_type, count in sorted(relation_types.items(), key=lambda x: x[1], reverse=True):
                print(f"  - {relation_type}: {count:,}")
        
        # æ˜¾ç¤ºæ ·ä¾‹æ•°æ®
        print(f"\nğŸ“ å…³ç³»è®°å½•æ ·ä¾‹ï¼ˆå‰3æ¡ï¼‰:")
        sample_cols = ['source_english_id', 'relationship_type', 'target_english_id', 'data_source']
        available_cols = [col for col in sample_cols if col in df_relationships.columns]
        if available_cols:
            print(df_relationships[available_cols].head(3).to_string(index=False))
        
        print("\n" + "="*60)
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        print("="*60)
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "ğŸ§ª Phase 1.2 é›†æˆæµ‹è¯•".center(60, "="))
    print()
    
    success = test_load_and_combine_data()
    
    if success:
        print("\nğŸ‰ é›†æˆæˆåŠŸ! æ–°æ¨¡å—å·¥ä½œæ­£å¸¸ã€‚\n")
        return 0
    else:
        print("\nğŸ’¥ é›†æˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚\n")
        return 1


if __name__ == "__main__":
    exit(main())
